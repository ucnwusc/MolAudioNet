# MolAudioNet
Molecular Audio Net
Molecular AI has transformed drug discovery and materials science through symbolic representations (SMILES, InChI, molecular formulas) and graph structures. Yet a third modality remains unexplored: audio. We introduce MolAudioNet, a systematic framework for encoding molecular structures as audio waveforms, creating the first large-scale molecular audio dataset of 50,284 compounds. Our multimodal architecture---combining text, graph, and audio encoders---achieves state-of-the-art results: \textbf{95.2\% accuracy} on drug classification (15\% improvement over text-only), and \textbf{$R^2$=0.89} on property regression (23\% improvement). Ablation studies reveal audio uniquely captures stereochemical and conformational information missed by other modalities. This work represents a step toward \textit{molecular foundation models} that understand chemistry through comprehensive multimodal representations, analogous to how large language models transformed NLP. We release MolAudioNet-50K, code, and pre-trained models to accelerate research in multimodal molecular intelligence.
